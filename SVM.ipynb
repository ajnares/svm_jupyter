{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89c4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5c1d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d077ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d7d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20348 images belonging to 4 classes.\n",
      "Found 10180 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/Admin/Desktop/school works/beans/data/train',\n",
    "                                                target_size= (64,64),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/Admin/Desktop/school works/beans/data/test',\n",
    "                                            target_size= (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd60193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e046168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac81bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = tf.keras.models.Sequential()\n",
    "svm.add(tf.keras.layers.Conv2D(filters=32, padding=\"same\", kernel_size=3, activation='relu', strides=2, input_shape=[64,64,3]))\n",
    "svm.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "svm.add(tf.keras.layers.Flatten())\n",
    "svm.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "svm.add(Dense(4, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation\n",
    "             ='softmax'))\n",
    "\n",
    "svm.compile(optimizer ='adam', loss='squared_hinge', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2041e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,050,116\n",
      "Trainable params: 1,050,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "svm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77443d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "636/636 [==============================] - 935s 1s/step - loss: 1.0976 - accuracy: 0.3248 - val_loss: 1.0872 - val_accuracy: 0.3257\n",
      "Epoch 2/20\n",
      "636/636 [==============================] - 888s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 3/20\n",
      "636/636 [==============================] - 911s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 4/20\n",
      "636/636 [==============================] - 906s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 5/20\n",
      "636/636 [==============================] - 770s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 6/20\n",
      "636/636 [==============================] - 804s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 7/20\n",
      "636/636 [==============================] - 730s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 8/20\n",
      "636/636 [==============================] - 723s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 9/20\n",
      "636/636 [==============================] - 745s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 10/20\n",
      "636/636 [==============================] - 804s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 11/20\n",
      "636/636 [==============================] - 720s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 12/20\n",
      "636/636 [==============================] - 810s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 13/20\n",
      "636/636 [==============================] - 816s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 14/20\n",
      "636/636 [==============================] - 823s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 15/20\n",
      "636/636 [==============================] - 871s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 16/20\n",
      "636/636 [==============================] - 855s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 17/20\n",
      "636/636 [==============================] - 832s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 18/20\n",
      "636/636 [==============================] - 796s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 19/20\n",
      "636/636 [==============================] - 814s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n",
      "Epoch 20/20\n",
      "636/636 [==============================] - 811s 1s/step - loss: 1.0873 - accuracy: 0.3254 - val_loss: 1.0871 - val_accuracy: 0.3257\n"
     ]
    }
   ],
   "source": [
    "svm.compile(optimizer ='adam', loss='hinge', metrics =['accuracy'])\n",
    "r=svm.fit(x = training_set,validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b060cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "svm.save('model_svm_beans.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cce9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('model_svm_beans.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TEST\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/Admin/Desktop/school works/beans/data/test/Grade 2/IMG_0004.JPEG', target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca5061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d7117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05aded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
